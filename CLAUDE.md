# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Berg Operator is a Kubernetes operator written in Rust that automates the lifecycle management of CTF (Capture The Flag) challenge instances. It is a purely Kubernetes-native controller that creates and manages challenge infrastructure based on ChallengeInstance custom resources.

**Key Principles:**
- Database-free: All state stored in Kubernetes API server
- Stateless controller: Can be restarted without losing state
- Declarative management: Instance lifecycle defined through Kubernetes CRs
- Event-driven reconciliation: React to ChallengeInstance CR changes

## Development Commands

### Building
```bash
cargo build           # Build the project
cargo build --release # Build optimized release binary
```

### Testing
```bash
cargo test           # Run all tests
cargo test <name>    # Run specific test
```

### Development Environment
This project uses devenv for environment management:
```bash
devenv shell  # Enter development shell with all dependencies
```

## Architecture

### Controller Responsibilities
The controller ONLY manages Kubernetes resources. It does NOT:
- Manage Challenge CR lifecycle (handled by challenge authors)
- Handle player authentication/authorization (handled by Berg API)
- Generate flags (handled by Berg API before CR creation)
- Persist to database (handled by Berg API via CR watch)
- Validate flag submissions or track scoring (handled by Berg API)

### What the Controller Does Manage
- ChallengeInstance custom resource reconciliation
- Namespace creation and cleanup (per-owner isolation)
- Deployment, Service, ConfigMap, PodDisruptionBudget creation
- Gateway API HTTPRoute and TLSRoute resources
- Cilium NetworkPolicy configuration
- Flag injection from CR spec (environment, file, or executable modes)
- Timeout-based instance termination
- Status reporting and condition tracking

### Reconciliation State Machine

The controller implements a state machine with these phases:

1. **Pending** → Initial state when ChallengeInstance is created
2. **Creating** → Controller creates namespace and all owned resources
3. **Starting** → Deployments created, waiting for pods to be ready
4. **Running** → All pods ready, services accessible
5. **Terminating** → Namespace deletion in progress
6. **Terminated** → All resources cleaned up (CR can be deleted)
7. **Failed** → Unrecoverable error during reconciliation

### Resource Naming Pattern

- Instance namespace: `challenge-<ownerId>` (ownerId is a UUID)
- Finalizer: `challengeinstance.berg.norelect.ch/finalizer`
- All resources use owner references for automatic garbage collection

### Flag Injection Modes

Flags are provided in `spec.flag` (pre-generated by Berg API). The controller reads the Challenge CR to determine injection mode:

1. **Environment Variable**: Inject as env var (e.g., `FLAG=flag{...}`)
2. **File Content**: Mount flag as file via ConfigMap
3. **Executable**: Generate ELF binary embedding flag, mount as executable with CAP_DAC_OVERRIDE dropped

Path entropy substitution: `{entropy}` in paths is replaced with 12 random hex characters.

## Custom Resource Definitions

### ChallengeInstance CRD
- API Group: `berg.norelect.ch/v1`
- Kind: `ChallengeInstance`
- Short names: `ci`, `instance`
- Scope: Namespaced

**Key Spec Fields:**
- `challengeRef.name`: Reference to Challenge resource
- `challengeRef.namespace`: Optional namespace (defaults to controller's challenge namespace)
- `ownerId`: UUID of player/team owning this instance
- `flag`: Pre-generated flag (from Berg API)
- `timeout`: Duration before auto-termination (default: 2h)
- `terminationReason`: Enum - UserRequest, Timeout, AdminTermination

**Key Status Fields:**
- `instanceId`: UUID generated by controller
- `phase`: Current lifecycle phase
- `namespace`: Kubernetes namespace containing instance resources
- `services[]`: Public service endpoints with hostname/port
- `startedAt`, `readyAt`, `terminatedAt`, `expiresAt`: Timestamps
- `conditions[]`: Detailed status conditions for troubleshooting

### Challenge CRD (Read-Only)
The controller reads from the existing Challenge CRD but never modifies it. Key fields:
- `spec.containers[]`: Container specifications to deploy
- `spec.containers[].ports[]`: Networking configuration
- `spec.containers[].dynamicFlag`: Flag injection mode
- `spec.allowOutboundTraffic`: Network policy control

## Important Implementation Details

### Reconciliation Idempotency
All reconciliation actions must be idempotent. The controller should:
- Compare desired state with current state
- Only create/update resources when necessary
- Use owner references for automatic cleanup
- Update status conditions accurately

### Timeout Management
- Default timeout: 2h (configurable via `spec.timeout`)
- Controller periodically checks `status.expiresAt`
- On expiration: Set `spec.terminationReason` to `Timeout` and delete CR
- Finalizer ensures namespace cleanup before CR deletion

### Network Isolation
Each instance gets:
- Dedicated namespace: `challenge-<ownerId>`
- Cilium NetworkPolicy restricting egress:
  - Allow DNS to kube-dns (with optional FQDN filtering)
  - Allow traffic to pods in same namespace
  - Allow traffic to host for OIDC callbacks
  - Conditionally allow internet (based on `allowOutboundTraffic`)

### Security Considerations
- Dedicated ServiceAccount with minimal RBAC
- No database credentials needed (stateless)
- Per-owner namespace isolation
- Flags never logged or exposed in metrics
- Executable flags have CAP_DAC_OVERRIDE dropped

## Status Conditions

The controller maintains these status conditions:

- `ChallengeFound`: Referenced Challenge CR exists
- `FlagValidation`: Flag provided when required
- `NamespaceCreated`: Instance namespace created
- `NetworkPolicyCreated`: NetworkPolicy created
- `ServicesCreated`: All Services created
- `RoutesCreated`: All Routes created
- `DeploymentsCreated`: All Deployments created
- `PodsReady`: All pods Running and Ready
- `Healthy`: Pods remain healthy
- `NamespaceDeleted`: Cleanup complete

## Integration with Berg API

The Berg API:
1. Authenticates players
2. **Generates flags** (with suffix/leetify modes)
3. Creates ChallengeInstance CRs with pre-generated flags
4. Watches ChallengeInstance status updates
5. Synchronizes status to PostgreSQL database
6. Provides REST API endpoints

The controller only manages Kubernetes resources; all business logic lives in the API.

## Reference Documentation

For complete technical specifications, see `challenge-instance-controller-spec.md` which includes:
- Detailed reconciliation algorithms for each phase
- Complete CRD schemas
- RBAC requirements
- Configuration parameters
- Observability metrics and events
- Testing strategy
